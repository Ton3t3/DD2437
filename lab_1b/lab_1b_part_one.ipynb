{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ea0294c4",
      "metadata": {
        "id": "ea0294c4"
      },
      "source": [
        "# DD2437\n",
        "## Lab 1B - Part I\n",
        "\n",
        "**Group 26**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4612654",
      "metadata": {
        "id": "c4612654"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "from ipywidgets import interact, IntSlider, fixed, Play, ToggleButtons\n",
        "from matplotlib.ticker import MaxNLocator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c52d16dc",
      "metadata": {
        "id": "c52d16dc"
      },
      "outputs": [],
      "source": [
        "# Set seed\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BNjwCaIQyYbI",
      "metadata": {
        "id": "BNjwCaIQyYbI"
      },
      "source": [
        "## HYPERPARAMETER TUNNING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dl7PsZE0yao_",
      "metadata": {
        "id": "dl7PsZE0yao_"
      },
      "outputs": [],
      "source": [
        "nodes_hidden_layer = 0#4\n",
        "nodes_output_layer = 1\n",
        "number_iterations = 1\n",
        "step_length = 1\n",
        "number_epochs = 100\n",
        "learning_rate = 0.05\n",
        "alpha = 0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Fwr3YNWIy6kj",
      "metadata": {
        "id": "Fwr3YNWIy6kj"
      },
      "outputs": [],
      "source": [
        "def transfer_function(x):\n",
        "  return 2/(1+np.exp(-x))-1\n",
        "\n",
        "def der_transfer_function(x):\n",
        "  phi = transfer_function(x)\n",
        "  return (1+phi)*(1-phi)/2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "S47m6OD8vAzC",
      "metadata": {
        "id": "S47m6OD8vAzC"
      },
      "source": [
        "### 3.1.1 Classification of linearly non-separable data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UwkaTEsGu78w",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "UwkaTEsGu78w",
        "outputId": "58fcca0e-5d51-4e48-e972-bae88f4eb8f4"
      },
      "outputs": [],
      "source": [
        "n = 100\n",
        "mA = np.array([1.0, 0.3])\n",
        "mB = np.array([0.0, -0.1])\n",
        "sigmaA = 0.2\n",
        "sigmaB = 0.3\n",
        "half_1 = np.random.randn(int(np.round(0.5*n)),1) * sigmaA - mA[0]\n",
        "half_2 = np.random.randn(int(np.round(0.5*n)),1) * sigmaA + mA[0]\n",
        "classA_0 = np.vstack((half_1, half_2))\n",
        "classA_1 = np.random.randn(n,1) * sigmaA + mA[1]\n",
        "classA = np.hstack((classA_0, classA_1))\n",
        "classB = np.random.randn(n, 2) * sigmaB + mB\n",
        "\n",
        "plt.scatter(classA[:, 0], classA[:, 1], color='blue', label='Class A')\n",
        "plt.scatter(classB[:, 0], classB[:, 1], color='red', label='Class B')\n",
        "plt.title('Generated Data for Class A and Class B')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cTJFcgXXzl2Q",
      "metadata": {
        "id": "cTJFcgXXzl2Q"
      },
      "outputs": [],
      "source": [
        "def forward_pass(w, v, X):\n",
        "  '''Hidden layer'''\n",
        "  ones = np.ones(X.shape[1]).reshape((1, X.shape[1]))\n",
        "  # print(X.shape,ones.shape)\n",
        "  X_in = np.vstack((X, ones))\n",
        "  # print(X_in, X_in.shape)\n",
        "  h_in = np.dot(w,X_in) # (hidden,2n)\n",
        "  # print(h_in, h_in.shape)\n",
        "  h_out = transfer_function(h_in) #(hidden, 2n)\n",
        "  # print(h_out, h_out.shape)\n",
        "  '''Output layer'''\n",
        "  H = np.vstack((h_out, ones))\n",
        "  # print(H, H.shape)\n",
        "  o_in = np.dot(v,H)\n",
        "  # print(o_in, o_in.shape)\n",
        "  o_out = transfer_function(o_in)\n",
        "  # print(o_out, o_out.shape)\n",
        "  return h_in, h_out, o_in, o_out, X_in, H\n",
        "\n",
        "def backward_pass(h_in, h_out, o_in, o_out, t, v):\n",
        "  phi_dot_o = der_transfer_function(o_in)\n",
        "  delta_o = np.multiply((o_out - t), phi_dot_o)\n",
        "  # print(delta_o, delta_o.shape)\n",
        "  phi_dot_h = der_transfer_function(h_in)\n",
        "  delta_h = np.multiply((np.dot(np.transpose(v[:,:-1]),delta_o)),phi_dot_h) # WE DON'T USE THE BIAS COLUMN FROM THE V MATRIX!!!\n",
        "  # print(delta_h, delta_h.shape)\n",
        "  return delta_o, delta_h\n",
        "\n",
        "def backprop(classA_train, classB_train, hidden_dim, classA_val=None, classB_val=None, batch_size=None):\n",
        "\n",
        "  X_train = np.vstack((classA_train, classB_train))\n",
        "  t_train = np.hstack((-np.ones(classA_train.shape[0]), np.ones(classB_train.shape[0])))\n",
        "  perm = np.random.permutation(X_train.shape[0])\n",
        "  X_train, t_train = X_train[perm], t_train[perm]\n",
        "  X_train = np.transpose(X_train) # (2,2n)\n",
        "  t_train = np.transpose(t_train) # (1,2n)\n",
        "\n",
        "  '''\n",
        "  If validation data is provided, use it. Otherwise,\n",
        "  we reuse training data for validation.\n",
        "  '''\n",
        "  if classA_val is not None and classB_val is not None:\n",
        "    X_val = np.vstack((classA_val, classB_val))\n",
        "    t_val = np.hstack((-np.ones(classA_val.shape[0]), np.ones(classB_val.shape[0])))\n",
        "    perm = np.random.permutation(X_val.shape[0])\n",
        "    X_val, t_val = X_val[perm], t_val[perm]\n",
        "    X_val = np.transpose(X_val) # (2,2n)\n",
        "    t_val = np.transpose(t_val) # (1,2n)\n",
        "  else:\n",
        "    X_val = X_train\n",
        "    t_val = t_train\n",
        "\n",
        "  w_history = []\n",
        "  v_history = []\n",
        "  classification_accuracy_history = []\n",
        "  mse_history = []\n",
        "  w = np.random.random((hidden_dim,3)).reshape(hidden_dim,3) #(hidden, 2+bias)\n",
        "  v = np.random.random((nodes_output_layer, hidden_dim+1)).reshape(nodes_output_layer,hidden_dim+1) #(output, hidden+bias)\n",
        "  # print(f'W: {w}, {w.shape}')\n",
        "  # print(f'V: {v}, {v.shape}')\n",
        "  delta_w = 0\n",
        "  delta_v = 0\n",
        "  # For each epoch\n",
        "  for _ in range(number_epochs):\n",
        "    # For each batch (unless batch_size is None, then we use the whole set)\n",
        "    for i in range(0, X_train.shape[1], batch_size if batch_size is not None else X_train.shape[1]):\n",
        "      if batch_size is not None:\n",
        "        X_batch = X_train[:, i:i+batch_size]\n",
        "        t_batch = t_train[i:i+batch_size]\n",
        "      else:\n",
        "        X_batch = X_train\n",
        "        t_batch = t_train\n",
        "      '''1st: FORWARD PASS: Activities of the nodes are computed layer for layer'''\n",
        "      h_in, h_out, o_in, o_out, X_bias, H_bias = forward_pass(w, v, X_batch)\n",
        "      ''' 2nd: BACKWARD PASS: Error signal (delta) computed for each node'''\n",
        "      delta_o, delta_h = backward_pass(h_in, h_out, o_in, o_out, t_batch, v)\n",
        "      ''' 3rd: WEIGHT UPDATE'''\n",
        "      delta_w = delta_w*alpha - (1-alpha)*np.dot(delta_h, np.transpose(X_bias))\n",
        "      delta_v = delta_v*alpha - (1-alpha)*np.dot(delta_o, np.transpose(H_bias))\n",
        "      # print(delta_v)\n",
        "      w += learning_rate*delta_w\n",
        "      v += learning_rate*delta_v\n",
        "      # print(v)\n",
        "    # We only check accuracy and MSE after each epoch, not for each batch\n",
        "    classification_accuracy_history.append(check_accuracy(w,v,X_val,t_val))\n",
        "    mse_history.append(mse(w,v,X_val,t_val))\n",
        "    w_history.append(w.copy())\n",
        "    v_history.append(v.copy())\n",
        "    #print(f'Epoch {_+1}/{number_epochs} - Accuracy: {accuracy*100:.2f}%')\n",
        "  hidden_node_accuracy = check_accuracy(w,v,X_val,t_val)\n",
        "  # print(v_history)\n",
        "  return np.array(w_history), np.array(v_history), np.array(classification_accuracy_history), np.array(mse_history), hidden_node_accuracy\n",
        "\n",
        "\n",
        "def check_accuracy(w,v,X,t):\n",
        "  _, _, Z_data, _, _, _ = forward_pass(w, v, X)\n",
        "  labels_pred = np.sign(Z_data).flatten()\n",
        "  correct = 0\n",
        "  for i in range(labels_pred.shape[0]):\n",
        "      if labels_pred[i] == t[i]:\n",
        "          correct += 1\n",
        "  return correct / X.shape[1]\n",
        "\n",
        "'''\n",
        "Mean Squared Error accuracy function\n",
        "Follows the formula: MSE = 1/N * sum((t - Z_data)^2) / 4\n",
        "Note that we're dividing by 4 to account for worst case\n",
        "scenario where t = 1 and Z_data = -1.\n",
        "'''\n",
        "def mse(w, v, X, t):\n",
        "  _, _, Z_data, _, _, _ = forward_pass(w, v, X)\n",
        "  labels_pred = np.sign(Z_data).flatten()\n",
        "  return np.mean((t - labels_pred)**2) / 4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Olw_YT41xSwo",
      "metadata": {
        "id": "Olw_YT41xSwo"
      },
      "source": [
        "#### Hidden nodes effect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaQvft1GxR11",
      "metadata": {
        "id": "eaQvft1GxR11"
      },
      "outputs": [],
      "source": [
        "def plot_decision_boundary(epoch_idx, title, w_history, v_history, classA, classB, hidden_dim):\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "\n",
        "    # Plot data points\n",
        "    ax.scatter(classA[:, 0], classA[:, 1], color='blue', label='Class A')\n",
        "    ax.scatter(classB[:, 0], classB[:, 1], color='red', label='Class B')\n",
        "\n",
        "    # Then we create the decision boundary line\n",
        "    x_boundry = np.linspace(-3, 3, 100)\n",
        "    w = np.array(w_history[epoch_idx]).reshape(hidden_dim,3)\n",
        "    v = np.array(v_history[epoch_idx]).reshape(nodes_output_layer, hidden_dim+1)\n",
        "    # print(w, w.shape)\n",
        "    # print(v,v.shape)\n",
        "\n",
        "    xx, yy = np.meshgrid(\n",
        "    np.linspace(-2, 2, 400),\n",
        "    np.linspace(-2, 2, 400)\n",
        "          )\n",
        "    X_grid = np.vstack([xx.ravel(), yy.ravel()])\n",
        "\n",
        "    _, _, o_in, _, _, _ = forward_pass(w, v, X_grid)\n",
        "\n",
        "    Z = o_in\n",
        "    Z_plot = Z.reshape(xx.shape)\n",
        "    plt.contourf(xx, yy, Z_plot, levels=50, cmap='coolwarm', alpha=0.4)\n",
        "    plt.contour(xx, yy, Z_plot, levels=[0], colors='black', linewidths=2)\n",
        "\n",
        "    '''OBSERVING BOUNDARIES FROM INPUT TO HIDDEN LAYER'''\n",
        "    # for i in range(hidden_dim):\n",
        "    #   y_boundry = - (w[i,0]/w[i,1]) * x_boundry - (w[i,2]/w[i,1])\n",
        "    #   ax.plot(x_boundry, y_boundry, label=f\"Decision boundary {i}\")\n",
        "\n",
        "    '''OBSERVING BOUNDARIES FROM INPUT TO OUTPUT LAYER'''\n",
        "    # for i in range(nodes_output_layer):\n",
        "    #   v_a = v[:,:-1]\n",
        "    #   print(f\"v_a: {v_a}, {v_a.shape}\")\n",
        "    #   const_1 = (np.dot(v_a[i,:],w[:,0])).T #Not necessary T\n",
        "    #   const_2 = (np.dot(w[:,2].T,v_a[i,:]) + v[i,-1])\n",
        "    #   const_den = (np.dot(v_a[i,:],w[:,1])).T #Not necessary T\n",
        "    #   # print(const_2)\n",
        "    #   y_boundry = - x_boundry *  const_1/const_den- const_2/const_den\n",
        "    #   ax.plot(x_boundry, y_boundry, label=f\"Decision boundary {i}\")\n",
        "\n",
        "    ax.set_xlim(-2, 2)\n",
        "    ax.set_ylim(-2, 2)\n",
        "    ax.legend()\n",
        "    ax.set_title(title)\n",
        "\n",
        "\n",
        "def plot_accuracy(mse_history, classification_accuracy_history, title, title_suffix=''):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(classification_accuracy_history, label='Classification Accuracy')\n",
        "    plt.plot(mse_history, label='MSE')\n",
        "    plt.title(title + \" \" + title_suffix)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.ylim(0, 1)\n",
        "    plt.grid()\n",
        "    plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def plot_node_accuracy(node_accuracy_history, title, title_suffix=''):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(node_accuracy_history, label='Accuracy')\n",
        "    plt.title(title + \" \" + title_suffix)\n",
        "    plt.xlabel('Number of hidden layer nodes')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.ylim(0, 1)\n",
        "    plt.grid()\n",
        "    plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_yPB_PmOnJ0C",
      "metadata": {
        "id": "_yPB_PmOnJ0C"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate(classA_train, classB_train, classA_val=None, classB_val=None, title_suffix='', batch_size=None, desired_nodes_hidden_layers = [1]):\n",
        "  hidden_node_accuracy_history = []\n",
        "  for i in desired_nodes_hidden_layers:\n",
        "    w_history, v_history, classification_accuracy_history, mse_history, hidden_node_accuracy= backprop(classA_train, classB_train, i, classA_val, classB_val, batch_size=batch_size)\n",
        "    title = f'Backprop with two-layer perceptron network (Hidden layer: {i})'\n",
        "    if classA_val is None and classB_val is None: #In order to plot something\n",
        "      classA_plot = classA_train\n",
        "      classB_plot = classB_train\n",
        "    else:\n",
        "      classA_plot = classA_val\n",
        "      classB_plot = classB_val\n",
        "    plot_decision_boundary(epoch_idx=number_epochs-1,\n",
        "                          title=title,\n",
        "                          w_history=w_history,\n",
        "                          v_history=v_history,\n",
        "                          classA=classA_plot,\n",
        "                          classB=classB_plot,\n",
        "                          hidden_dim=i)\n",
        "    plot_accuracy(mse_history, classification_accuracy_history, title, title_suffix)\n",
        "    hidden_node_accuracy_history.append(hidden_node_accuracy)\n",
        "    # print(np.array(hidden_node_accuracy_history).shape)\n",
        "  plot_node_accuracy(np.array(hidden_node_accuracy_history), f'Backdrop accuracy of two-layer perceptron network (Epoch:{number_epochs})')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40fdab08",
      "metadata": {
        "id": "40fdab08"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Split Data takes a list of data points and divides it\n",
        "into two groups: training data and validation data,\n",
        "based on a ration 0-1.\n",
        "'''\n",
        "def split_data(data, n_train):\n",
        "    # Shuffle data identically each time\n",
        "    np.random.seed(42)\n",
        "    perm = np.random.permutation(data.shape[0])\n",
        "    data = data[perm]\n",
        "    # Calculate split\n",
        "    n = data.shape[0] * n_train // 1\n",
        "    n = int(n)\n",
        "    train_data = data[:n]\n",
        "    val_data = data[n:]\n",
        "    return train_data, val_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "257cb5d0",
      "metadata": {
        "id": "257cb5d0"
      },
      "source": [
        "### All data for training and vadliation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8602eec0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8602eec0",
        "outputId": "fb79f4c5-fcca-4c00-d8fe-2371296dd3b2"
      },
      "outputs": [],
      "source": [
        "train_and_evaluate(classA, classB, title_suffix='(All data)', desired_nodes_hidden_layers=range(1,16))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30060a75",
      "metadata": {
        "id": "30060a75"
      },
      "source": [
        "### Random 75/25 split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f93aa02",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2f93aa02",
        "outputId": "e4d4d148-1a26-4d9e-f32f-2f4d2095eb4a"
      },
      "outputs": [],
      "source": [
        "classA_train, classA_val = split_data(classA, 0.75)\n",
        "classB_train, classB_val = split_data(classB, 0.75)\n",
        "train_and_evaluate(classA_train, classB_train, classA_val, classB_val, title_suffix='(75%-25%)', desired_nodes_hidden_layers=[10])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e9f219f",
      "metadata": {
        "id": "4e9f219f"
      },
      "source": [
        "### Random 50/50 split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80c1cd06",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "80c1cd06",
        "outputId": "91f42e5d-a972-44b7-e81c-fc8c19fda85f"
      },
      "outputs": [],
      "source": [
        "classA_train, classA_val = split_data(classA, 0.50)\n",
        "classB_train, classB_val = split_data(classB, 0.50)\n",
        "train_and_evaluate(classA_train, classB_train, classA_val, classB_val, title_suffix='(50%-50%)', desired_nodes_hidden_layers=[10])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4a6335a",
      "metadata": {
        "id": "b4a6335a"
      },
      "source": [
        "### 20% from subset 1 of A and 80% form subset 2 of A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fa1ae8c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1fa1ae8c",
        "outputId": "27491207-5a5a-48c0-ba0a-9ac75e8ef80f"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Note that we manually split classA into two parts to regain the\n",
        "old two groups where first half has mean at -1 and second half at +1.\n",
        "Then we split those two halves into training and validation sets\n",
        "with 20%-80% and combine them back together.\n",
        "'''\n",
        "classA_one_train, classA_one_val = split_data(classA[:int(np.round(0.5*n))], 0.20)\n",
        "classA_two_train, classA_two_val = split_data(classA[int(np.round(0.5*n)):], 0.80)\n",
        "classA_train = np.vstack((classA_one_train, classA_two_train))\n",
        "classA_val = np.vstack((classA_one_val, classA_two_val))\n",
        "classB_train = classB\n",
        "classB_val = classB\n",
        "print(\"classA_train.shape:\", classA_train.shape)\n",
        "print(\"classA_val.shape:\", classA_val.shape)\n",
        "train_and_evaluate(classA_train, classB_train, classA_val, classB_val, title_suffix='(20%-80% from class A)', desired_nodes_hidden_layers=[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daaebcfd",
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Exploring the different in terms of validation results comparing\n",
        "batch vs sequential updates. Where batch is the whole training.\n",
        "'''\n",
        "classA_train, classA_val = split_data(classA, 0.75)\n",
        "classB_train, classB_val = split_data(classB, 0.75)\n",
        "train_and_evaluate(classA_train, classB_train, classA_val, classB_val, title_suffix='(Batch)', batch_size=None, desired_nodes_hidden_layers=[10])\n",
        "train_and_evaluate(classA_train, classB_train, classA_val, classB_val, title_suffix='(Sequential)', batch_size=1, desired_nodes_hidden_layers=[10])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
